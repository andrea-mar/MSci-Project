{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP for Text Classfication to select only the ASD relevant subreddits - see discussion in *reddit_data.ipynb* : \n",
    "\n",
    "'From the above analysis we can see that the first 10 subreddits , by number of subscribers, do not seem to be related to ASD. \n",
    "\n",
    "=> Use NLP to filter out the ASD relavant subreddits : display_name + title + public_description + header_title + description (Text classification task - target categories: ASD vs Other. ) - Manually annotate 40% out of 534 subreddits -> train different models -> choose the best one to classify the rest 60% and get the final subreddits list.\n",
    "\n",
    "As the private subreddits' data can't be accessed, these will be excluded from the analisys. The subreddits dataset will only inlcude those that are listed as 'public' or 'restricted' (= everyone can read the data but only certain people can post).\n",
    "\n",
    "Features used: display_name + title + public_description + header_title + description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for NLP:\n",
    "\n",
    "1. get data (40% asd_final_rows_list.csv) and annotate it \n",
    "2. text extraction and cleanup - merge relevant information into one text column, remove punctuation/spelling mistakes etc. \n",
    "3. pre-processing:\n",
    "    3.1 split text into tokens/words (=sentence segmentation/ tokanisation NLTK or Spcy or AutoTokenizer if using transformers)\n",
    "    3.3 stemming (=remove prefixes and sufixes) and lemmatization (=get the base word - ext ate becomes (to)eat)\n",
    "4. feature engineering (= convert text / document into vector)\n",
    "    count-vector\n",
    "    tf-idf\n",
    "    one-hot encode - not really used due to size and sparcity problems\n",
    "    word/token-emebeding\n",
    "5. apply classifier ( any machine learning model classifier ) - use gridSearchCV to see which is the best performing classifier ?\n",
    "6. evaluate  model: Accuracy, Precision, Recall, F1 score ( if not good , go back to preprocessing step )\n",
    "7. Deploy\n",
    "8. Monitor and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get data  - whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 534 entries, 0 to 533\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             534 non-null    int64  \n",
      " 1   restrict_posting       534 non-null    bool   \n",
      " 2   display_name           534 non-null    object \n",
      " 3   title                  534 non-null    object \n",
      " 4   display_name_prefixed  534 non-null    object \n",
      " 5   subscribers            534 non-null    int64  \n",
      " 6   name                   534 non-null    object \n",
      " 7   public_description     506 non-null    object \n",
      " 8   community_reviewed     534 non-null    bool   \n",
      " 9   created                534 non-null    float64\n",
      " 10  subreddit_type         534 non-null    object \n",
      " 11  id                     534 non-null    object \n",
      " 12  over18                 534 non-null    bool   \n",
      " 13  header_title           81 non-null     object \n",
      " 14  description            393 non-null    object \n",
      " 15  url                    534 non-null    object \n",
      " 16  created_utc            534 non-null    float64\n",
      " 17  _path                  534 non-null    object \n",
      " 18  lang                   534 non-null    object \n",
      "dtypes: bool(3), float64(2), int64(2), object(12)\n",
      "memory usage: 68.4+ KB\n"
     ]
    }
   ],
   "source": [
    "asd_subs_df = pd.read_csv('asd_final_rows_list.csv')\n",
    "asd_subs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 534 entries, 0 to 533\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  534 non-null    object\n",
      " 1   display_name        534 non-null    object\n",
      " 2   title               534 non-null    object\n",
      " 3   public_description  506 non-null    object\n",
      " 4   header_title        81 non-null     object\n",
      " 5   description         393 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# select from the dataset only the text features neccesary for topic modeling + id \n",
    "# Features: display_name + title + public_description + header_title + description \n",
    "asd_subs_df = asd_subs_df[['id','display_name', 'title', 'public_description', 'header_title', 'description']]\n",
    "asd_subs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>title</th>\n",
       "      <th>public_description</th>\n",
       "      <th>header_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28lhh2</td>\n",
       "      <td>AutismRepresentation</td>\n",
       "      <td>Autism Awareness</td>\n",
       "      <td>A place for kind people who want to spread awa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b4rh</td>\n",
       "      <td>AspiePositive</td>\n",
       "      <td>AspiePositive: by aspies, for aspies | no hate...</td>\n",
       "      <td>If you have Asperger's, you are welcome. If yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**The Golden Rule: Be excellent to each other....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nwjjb</td>\n",
       "      <td>TrumpAutism</td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Autism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          display_name  \\\n",
       "0  28lhh2  AutismRepresentation   \n",
       "1   3b4rh         AspiePositive   \n",
       "2  2nwjjb           TrumpAutism   \n",
       "\n",
       "                                               title  \\\n",
       "0                                   Autism Awareness   \n",
       "1  AspiePositive: by aspies, for aspies | no hate...   \n",
       "2                                       Trump Autism   \n",
       "\n",
       "                                  public_description header_title  \\\n",
       "0  A place for kind people who want to spread awa...          NaN   \n",
       "1  If you have Asperger's, you are welcome. If yo...          NaN   \n",
       "2                                       Trump Autism          NaN   \n",
       "\n",
       "                                         description  \n",
       "0                                                NaN  \n",
       "1  **The Golden Rule: Be excellent to each other....  \n",
       "2                                       Trump Autism  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# public_description, header_title, description have missing data\n",
    "# in the reddit_data.ipynb the missing data appears as an empty string, meaning the subreddit does not have any text added to these sections\n",
    "# all NaN values will be replaced with an empty string \n",
    "# the text in each column will be agregated into one single text document as to include as much relevant words as possible for each subreddit\n",
    "asd_subs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "display_name            0\n",
       "title                   0\n",
       "public_description     28\n",
       "header_title          453\n",
       "description           141\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing data\n",
    "asd_subs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 534 entries, of which 28 are missing 'public_description' and 141 are missing 'description' and 453 are missing 'header_title'.\n",
    "\n",
    "display_name and title have no missing data.\n",
    "\n",
    "All text columns will be aggregated into one large text document ( to include all relevant words available for each subreddit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Clean up and text extraction - whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>title</th>\n",
       "      <th>public_description</th>\n",
       "      <th>header_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28lhh2</td>\n",
       "      <td>AutismRepresentation</td>\n",
       "      <td>Autism Awareness</td>\n",
       "      <td>A place for kind people who want to spread awa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b4rh</td>\n",
       "      <td>AspiePositive</td>\n",
       "      <td>AspiePositive: by aspies, for aspies | no hate...</td>\n",
       "      <td>If you have Asperger's, you are welcome. If yo...</td>\n",
       "      <td></td>\n",
       "      <td>**The Golden Rule: Be excellent to each other....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nwjjb</td>\n",
       "      <td>TrumpAutism</td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td></td>\n",
       "      <td>Trump Autism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          display_name  \\\n",
       "0  28lhh2  AutismRepresentation   \n",
       "1   3b4rh         AspiePositive   \n",
       "2  2nwjjb           TrumpAutism   \n",
       "\n",
       "                                               title  \\\n",
       "0                                   Autism Awareness   \n",
       "1  AspiePositive: by aspies, for aspies | no hate...   \n",
       "2                                       Trump Autism   \n",
       "\n",
       "                                  public_description header_title  \\\n",
       "0  A place for kind people who want to spread awa...                \n",
       "1  If you have Asperger's, you are welcome. If yo...                \n",
       "2                                       Trump Autism                \n",
       "\n",
       "                                         description  \n",
       "0                                                     \n",
       "1  **The Golden Rule: Be excellent to each other....  \n",
       "2                                       Trump Autism  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace NaN values with empty string ''\n",
    "# NaN valuse are only observed for text columns: public_description, header_title, description\n",
    "asd_subs_df = asd_subs_df.fillna('')\n",
    "asd_subs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 534 entries, 0 to 533\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  534 non-null    object\n",
      " 1   display_name        534 non-null    object\n",
      " 2   title               534 non-null    object\n",
      " 3   public_description  534 non-null    object\n",
      " 4   header_title        534 non-null    object\n",
      " 5   description         534 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# no more null values \n",
    "asd_subs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>title</th>\n",
       "      <th>public_description</th>\n",
       "      <th>header_title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28lhh2</td>\n",
       "      <td>AutismRepresentation</td>\n",
       "      <td>Autism Awareness</td>\n",
       "      <td>A place for kind people who want to spread awa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>AutismRepresentation Autism Awareness A place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b4rh</td>\n",
       "      <td>AspiePositive</td>\n",
       "      <td>AspiePositive: by aspies, for aspies | no hate...</td>\n",
       "      <td>If you have Asperger's, you are welcome. If yo...</td>\n",
       "      <td></td>\n",
       "      <td>**The Golden Rule: Be excellent to each other....</td>\n",
       "      <td>AspiePositive AspiePositive: by aspies, for as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nwjjb</td>\n",
       "      <td>TrumpAutism</td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td></td>\n",
       "      <td>Trump Autism</td>\n",
       "      <td>TrumpAutism Trump Autism Trump Autism  Trump A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          display_name  \\\n",
       "0  28lhh2  AutismRepresentation   \n",
       "1   3b4rh         AspiePositive   \n",
       "2  2nwjjb           TrumpAutism   \n",
       "\n",
       "                                               title  \\\n",
       "0                                   Autism Awareness   \n",
       "1  AspiePositive: by aspies, for aspies | no hate...   \n",
       "2                                       Trump Autism   \n",
       "\n",
       "                                  public_description header_title  \\\n",
       "0  A place for kind people who want to spread awa...                \n",
       "1  If you have Asperger's, you are welcome. If yo...                \n",
       "2                                       Trump Autism                \n",
       "\n",
       "                                         description  \\\n",
       "0                                                      \n",
       "1  **The Golden Rule: Be excellent to each other....   \n",
       "2                                       Trump Autism   \n",
       "\n",
       "                                                text  \n",
       "0  AutismRepresentation Autism Awareness A place ...  \n",
       "1  AspiePositive AspiePositive: by aspies, for as...  \n",
       "2  TrumpAutism Trump Autism Trump Autism  Trump A...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join text columns\n",
    "asd_subs_df[\"text\"] = asd_subs_df[[\"display_name\", \"title\", 'public_description', 'header_title', 'description']].apply(\" \".join, axis='columns')\n",
    "asd_subs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 534 entries, 0 to 533\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  534 non-null    object\n",
      " 1   display_name        534 non-null    object\n",
      " 2   title               534 non-null    object\n",
      " 3   public_description  534 non-null    object\n",
      " 4   header_title        534 non-null    object\n",
      " 5   description         534 non-null    object\n",
      " 6   text                534 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 29.3+ KB\n"
     ]
    }
   ],
   "source": [
    "asd_subs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28lhh2</td>\n",
       "      <td>AutismRepresentation</td>\n",
       "      <td>AutismRepresentation Autism Awareness A place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b4rh</td>\n",
       "      <td>AspiePositive</td>\n",
       "      <td>AspiePositive AspiePositive: by aspies, for as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nwjjb</td>\n",
       "      <td>TrumpAutism</td>\n",
       "      <td>TrumpAutism Trump Autism Trump Autism  Trump A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          display_name  \\\n",
       "0  28lhh2  AutismRepresentation   \n",
       "1   3b4rh         AspiePositive   \n",
       "2  2nwjjb           TrumpAutism   \n",
       "\n",
       "                                                text  \n",
       "0  AutismRepresentation Autism Awareness A place ...  \n",
       "1  AspiePositive AspiePositive: by aspies, for as...  \n",
       "2  TrumpAutism Trump Autism Trump Autism  Trump A...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the individual text columns for easier visualisation\n",
    "# only the text column will be used for the analysis\n",
    "# keep id and display_name - to identify subreddits\n",
    "asd_subs_df.drop(['title', 'public_description', 'header_title', 'description'], axis=1, inplace=True)\n",
    "asd_subs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327    autism__friends autism__friends a safe place f...\n",
       "381    videos /r/videos Reddit's main subreddit for v...\n",
       "482    mentalhealth Mental Health The Mental Health s...\n",
       "55     offmychest Off My Chest | A Safe Community for...\n",
       "273    AutismAndAddiction AutismAndAddiction A place ...\n",
       "3      nevergrewup When the body got older but the mi...\n",
       "97     IAmA IAmA I Am A, where the mundane becomes fa...\n",
       "90     WritteND WritteND A space for Neurodivergent w...\n",
       "204    asptrees asptrees the community for discussing...\n",
       "70     Autisme_France Autisme_France Groupe qui conce...\n",
       "478    Parenting Reddit Parenting - For those with ki...\n",
       "395    genetics Genetics, genes, and genomes For disc...\n",
       "472    Aspergians Aspergians A subreddit by and for s...\n",
       "50     aspieselfies aspieselfies a place for people w...\n",
       "306    AutisticPilking AutisticPilking Neco Arc is yo...\n",
       "115    TheAspieWorld The Aspie World - Aspergers & Au...\n",
       "109    CoronavirusUK CoronavirusUK Spreading news, ad...\n",
       "132    AskMeAnythingIAnswer We will try to answer any...\n",
       "351    AskTeenGirls r/AskTeenGirls: Ask girls questio...\n",
       "227    CasaAutistic CasaAutistic la casa autistic es ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invesitgate data further ( check text patterns that could be cleaned further )\n",
    "asd_subs_df['text'].sample(n=20, random_state=7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some terms appear in cammelCase - words capitalized and joined together - ex. *AutismAndAddiction*; Some terms are separated by _ : ex. *autism__friends*. We can separate these words by white spaces using regular expressions. However, some words are joined together with no clear delimitation (ex. *nevergrewup* ). In this situation we can't separate the words, but the deep leaning approach should be able to tokenize this text in a relevant way as these models split the text into single characters or groups of characters, or use bytes instead of characters/words ( see : Unigrams (Gasparetto et al., 2022)). To clean the data in this section cammelCase, dashes and underscores will be replaced by white spaces in the dataset. Concatenated strings of words with no clear delimitation will be left unchanged in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find and replace all cammelCase, dash and undreline joined words\n",
    "import re\n",
    "def split_words_by_space(text):\n",
    "    # split camelCase\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text) \n",
    "    # replace underscores and dashes with spaces\n",
    "    text = re.sub(r'[_-]+', ' ', text)  \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text words by spaces\n",
    "asd_subs_df['text'] = asd_subs_df['text'].apply(split_words_by_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327    autism friends autism friends a safe place for...\n",
       "381    videos /r/videos Reddit's main subreddit for v...\n",
       "482    mentalhealth Mental Health The Mental Health s...\n",
       "55     offmychest Off My Chest | A Safe Community for...\n",
       "273    Autism And Addiction Autism And Addiction A pl...\n",
       "3      nevergrewup When the body got older but the mi...\n",
       "97     IAm A IAm A I Am A, where the mundane becomes ...\n",
       "90     Writte ND Writte ND A space for Neurodivergent...\n",
       "204    asptrees asptrees the community for discussing...\n",
       "70     Autisme France Autisme France Groupe qui conce...\n",
       "478    Parenting Reddit Parenting   For those with ki...\n",
       "395    genetics Genetics, genes, and genomes For disc...\n",
       "472    Aspergians Aspergians A subreddit by and for s...\n",
       "50     aspieselfies aspieselfies a place for people w...\n",
       "306    Autistic Pilking Autistic Pilking Neco Arc is ...\n",
       "115    The Aspie World The Aspie World   Aspergers & ...\n",
       "109    Coronavirus UK Coronavirus UK Spreading news, ...\n",
       "132    Ask Me Anything IAnswer We will try to answer ...\n",
       "351    Ask Teen Girls r/Ask Teen Girls: Ask girls que...\n",
       "227    Casa Autistic Casa Autistic la casa autistic e...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd_subs_df['text'].sample(n=20, random_state=7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that some of the subreddis are not in english (227-CasaAutistic, 70-Autisme_France)\n",
    "\n",
    "Use langdetect to identify the language of the subreddits\n",
    "(https://pypi.org/project/langdetect/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect langage of subreddits text and save it in a 'lang' column\n",
    "from langdetect import detect\n",
    "asd_subs_df['lang'] = asd_subs_df['text'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18 rows are identified as not being english\n",
    "len(asd_subs_df[asd_subs_df['lang'] != 'en'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump Autism Trump Autism Trump Autism  Trump ...</td>\n",
       "      <td>lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aspergers After Dark Aspergers After Dark Migr...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>autismogang  autismogang</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Autisme France Autisme France Groupe qui conce...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Onions Cause Autism Onions Cause Autism Onions...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Asperger En Espanol Asperger En Espanol</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Vidar Autism Vidar Autism Autistic Vidar minec...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>aspergerinterests Asperger Interests</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Casa Autistic Casa Autistic la casa autistic e...</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Autistic Pride2 Autistic Pride2</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>girl parents autism girl parents autism</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Autism Art Autism Art welcome!</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Autism Gamers Autism Gamers</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Masked Autism Masked Autism</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Real Autists Romania Real Autists Romania Salu...</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Asperger Latam Asperger Latam Una comunidad en...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>Asper Minismo Asper Minismo El Asperminismo es...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Aspergers BR Aspergers BR Uma comunidade volta...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text lang\n",
       "2    Trump Autism Trump Autism Trump Autism  Trump ...   lv\n",
       "16   Aspergers After Dark Aspergers After Dark Migr...   da\n",
       "56                        autismogang  autismogang       tl\n",
       "70   Autisme France Autisme France Groupe qui conce...   fr\n",
       "89   Onions Cause Autism Onions Cause Autism Onions...   fr\n",
       "91          Asperger En Espanol Asperger En Espanol      es\n",
       "93   Vidar Autism Vidar Autism Autistic Vidar minec...   de\n",
       "214           aspergerinterests Asperger Interests       no\n",
       "227  Casa Autistic Casa Autistic la casa autistic e...   ca\n",
       "263                 Autistic Pride2 Autistic Pride2      ro\n",
       "283         girl parents autism girl parents autism      fr\n",
       "291                  Autism Art Autism Art welcome!      de\n",
       "300                     Autism Gamers Autism Gamers      de\n",
       "345                     Masked Autism Masked Autism      et\n",
       "388  Real Autists Romania Real Autists Romania Salu...   ro\n",
       "430  Asperger Latam Asperger Latam Una comunidad en...   es\n",
       "487  Asper Minismo Asper Minismo El Asperminismo es...   es\n",
       "512  Aspergers BR Aspergers BR Uma comunidade volta...   pt"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect rows manually to confirm language\n",
    "# set the maximum column width to display all content\n",
    "# pd.set_option('display.max_colwidth', 1)\n",
    "asd_subs_df[asd_subs_df['lang'] != 'en'][['text', 'lang']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the rows above, the following row are confirmed as not being in English: \n",
    "56, 70, 91, 227, 388, 430, 487, 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 526 entries, 0 to 533\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            526 non-null    object\n",
      " 1   display_name  526 non-null    object\n",
      " 2   text          526 non-null    object\n",
      " 3   lang          526 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 20.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop the non-english rows\n",
    "# 526 subreddits left in the dataset\n",
    "non_en_rows_indices = [56, 70, 91, 227, 388, 430, 487, 512]\n",
    "asd_subs_df = asd_subs_df.drop(non_en_rows_indices)\n",
    "asd_subs_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205    autismmemes autism memes Meme for people with\\...\n",
       "488    ASDcareers The Careers of People with ASD Livi...\n",
       "231    Gamingcirclejerk Gaming Circlejerk   Don Chead...\n",
       "104    autisticpeople Autism Spectrum Disorder News, ...\n",
       "263                   Autistic Pride2 Autistic Pride2   \n",
       "492    Baby Bumps Baby Bumps A place for pregnant red...\n",
       "236    hypersensitivity Hypersensitivity A place for ...\n",
       "3      nevergrewup When the body got older but the mi...\n",
       "323    Everything Science Everything Science /r/Every...\n",
       "506    aplusguide A+ Guide A+ Guide is a place for po...\n",
       "66     Neurodivergent LGBTQ Neurodivergent LGBTQ Neur...\n",
       "293    The Owl House The Owl House A subreddit for th...\n",
       "317    traaaaaaannnnnnnnnns If youre memes and im mem...\n",
       "529    Savant Savant This subreddit is dedicated to t...\n",
       "278    Debate Vaccines Debate Vaccines Debate and dis...\n",
       "51     intj analytical, conceptual and objective For ...\n",
       "216    gaspies A place for gay aspies For the aspies ...\n",
       "219    Council Of Autism Council Of Autism This is no...\n",
       "190    BPD Borderline Personality Disorder r/BPD is a...\n",
       "207    wallstreetbets wallstreetbets Like 4chan found...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd_subs_df['text'].sample(n=20, random_state=7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205    autismmemes autism memes Meme for people with ...\n",
       "488    ASDcareers The Careers of People with ASD Livi...\n",
       "231    Gamingcirclejerk Gaming Circlejerk   Don Chead...\n",
       "104    autisticpeople Autism Spectrum Disorder News, ...\n",
       "263                   Autistic Pride2 Autistic Pride2   \n",
       "492    Baby Bumps Baby Bumps A place for pregnant red...\n",
       "236    hypersensitivity Hypersensitivity A place for ...\n",
       "3      nevergrewup When the body got older but the mi...\n",
       "323    Everything Science Everything Science  Everyth...\n",
       "506    aplusguide A+ Guide A+ Guide is a place for po...\n",
       "66     Neurodivergent LGBTQ Neurodivergent LGBTQ Neur...\n",
       "293    The Owl House The Owl House A subreddit for th...\n",
       "317    traaaaaaannnnnnnnnns If youre memes and im mem...\n",
       "529    Savant Savant This subreddit is dedicated to t...\n",
       "278    Debate Vaccines Debate Vaccines Debate and dis...\n",
       "51     intj analytical, conceptual and objective For ...\n",
       "216    gaspies A place for gay aspies For the aspies ...\n",
       "219    Council Of Autism Council Of Autism This is no...\n",
       "190    BPD Borderline Personality Disorder  BPD is a ...\n",
       "207    wallstreetbets wallstreetbets Like 4chan found...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove \\n, /r/, r/, \\r  - these characters are not relevant\n",
    "asd_subs_df['text'] = asd_subs_df['text'].str.replace('\\n', ' ').str.replace('/r/', ' ').str.replace('r/', ' ').str.replace('\\r ', ' ')\n",
    "asd_subs_df['text'].sample(n=20, random_state=7) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex to replace non-word characters with space - these chars are not relevant to the text analysis\n",
    "def remove_non_word_chars(text):\n",
    "    cleaned_text = re.sub(r'[^A-Za-z0-9\\s]', ' ', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205    autismmemes autism memes Meme for people with ...\n",
       "488    ASDcareers The Careers of People with ASD Livi...\n",
       "231    Gamingcirclejerk Gaming Circlejerk   Don Chead...\n",
       "104    autisticpeople Autism Spectrum Disorder News  ...\n",
       "263                   Autistic Pride2 Autistic Pride2   \n",
       "492    Baby Bumps Baby Bumps A place for pregnant red...\n",
       "236    hypersensitivity Hypersensitivity A place for ...\n",
       "3      nevergrewup When the body got older but the mi...\n",
       "323    Everything Science Everything Science  Everyth...\n",
       "506    aplusguide A  Guide A  Guide is a place for po...\n",
       "66     Neurodivergent LGBTQ Neurodivergent LGBTQ Neur...\n",
       "293    The Owl House The Owl House A subreddit for th...\n",
       "317    traaaaaaannnnnnnnnns If youre memes and im mem...\n",
       "529    Savant Savant This subreddit is dedicated to t...\n",
       "278    Debate Vaccines Debate Vaccines Debate and dis...\n",
       "51     intj analytical  conceptual and objective For ...\n",
       "216    gaspies A place for gay aspies For the aspies ...\n",
       "219    Council Of Autism Council Of Autism This is no...\n",
       "190    BPD Borderline Personality Disorder  BPD is a ...\n",
       "207    wallstreetbets wallstreetbets Like 4chan found...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace non-word characters with space\n",
    "asd_subs_df['text'] = asd_subs_df['text'].apply(remove_non_word_chars)\n",
    "asd_subs_df['text'].sample(n=20, random_state=7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 526 entries, 0 to 533\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            526 non-null    object\n",
      " 1   display_name  526 non-null    object\n",
      " 2   text          526 non-null    object\n",
      " 3   lang          526 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 20.5+ KB\n"
     ]
    }
   ],
   "source": [
    "asd_subs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Get dataset for model selection -  anotated data\n",
    "40% of 526 = 210.4 -> split train-test 80%-20%( use cross validation as the dataset is small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autism Representation Autism Awareness A place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aspie Positive Aspie Positive  by aspies  for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump Autism Trump Autism Trump Autism  Trump ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Autism Representation Autism Awareness A place...\n",
       "1  Aspie Positive Aspie Positive  by aspies  for ...\n",
       "2  Trump Autism Trump Autism Trump Autism  Trump ..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd_subs_annotated_df = asd_subs_df[['text']]\n",
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210 entries, 205 to 282\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    210 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# select at random 40% of rows in the dataset to be manually annotated into 2 categories: asd and other\n",
    "# 40% out of 542 = 210 - > text clasiffication needs a large number of documents to train : at least 100 , ideally 1000 ( http://benschmidt.org/medhist16/index.html%3Fp=16.html#:~:text=Topic%20modeling%20can%20work%20on,short%20as%20a%20paragraph%20apiece.)\\\n",
    "# it can be done with this dataset but it very close to the minumm limit ( limitation )\n",
    "np.random.seed(7)\n",
    "asd_subs_annotated_df = asd_subs_annotated_df.sample(frac=0.4)\n",
    "asd_subs_annotated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data in a csv file to be annotated\n",
    "asd_subs_annotated_df.to_csv('annotated_data/asd_subs_to_annotate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  210 non-null    int64 \n",
      " 1   text        210 non-null    object\n",
      " 2   Category    210 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# load annotated dataset\n",
    "data_path = 'annotated_data/asd_subs_annotated.csv'\n",
    "asd_subs_annotated_df = pd.read_csv(data_path)\n",
    "asd_subs_annotated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205</td>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231</td>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text Category\n",
       "0         205  autismmemes autism memes Meme for people with ...      asd\n",
       "1         488  ASDcareers The Careers of People with ASD Livi...      asd\n",
       "2         231  Gamingcirclejerk Gaming Circlejerk   Don Chead...    other"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text Category\n",
       "Unnamed: 0                                                            \n",
       "205         autismmemes autism memes Meme for people with ...      asd\n",
       "488         ASDcareers The Careers of People with ASD Livi...      asd\n",
       "231         Gamingcirclejerk Gaming Circlejerk   Don Chead...    other"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unnamed: 0 is the index in the original dataset\n",
    "# this column was changed by apple's Numbers program when the file was annotated\n",
    "# set it as the index ( to keep the original indexes of the subreddits )\n",
    "asd_subs_annotated_df.set_index('Unnamed: 0', inplace=True)\n",
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text Category\n",
       "205  autismmemes autism memes Meme for people with ...      asd\n",
       "488  ASDcareers The Careers of People with ASD Livi...      asd\n",
       "231  Gamingcirclejerk Gaming Circlejerk   Don Chead...    other"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the index column name\n",
    "asd_subs_annotated_df.index.names = [None]\n",
    "# category contains 2 classes : asd (=autism related) and other (= not autism ralated)\n",
    "# the annotations were made by the author alone\n",
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text Category\n",
       "205  autismmemes autism memes Meme for people with ...      asd\n",
       "488  ASDcareers The Careers of People with ASD Livi...      asd\n",
       "231  Gamingcirclejerk Gaming Circlejerk   Don Chead...    other"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category contains 2 classes : asd (=autism related) and other (= not autism ralated)\n",
    "# the annotations were made by the author alone\n",
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asd</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>gaspies A place for gay aspies For the aspies ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Baby Bumps Baby Bumps A place for pregnant red...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asd</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ohter</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ask Me Anything IAnswer We will try to answer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text                                                               \n",
       "         count unique                                                top freq\n",
       "Category                                                                     \n",
       "Asd          6      6  gaspies A place for gay aspies For the aspies ...    1\n",
       "Other        4      4  Baby Bumps Baby Bumps A place for pregnant red...    1\n",
       "asd        107    107  autismmemes autism memes Meme for people with ...    1\n",
       "ohter        1      1  Ask Me Anything IAnswer We will try to answer ...    1\n",
       "other       92     92  Gamingcirclejerk Gaming Circlejerk   Don Chead...    1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics\n",
    "asd_subs_annotated_df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asd</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ohter</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ask Me Anything IAnswer We will try to answer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text                                                               \n",
       "         count unique                                                top freq\n",
       "Category                                                                     \n",
       "asd        113    113  autismmemes autism memes Meme for people with ...    1\n",
       "ohter        1      1  Ask Me Anything IAnswer We will try to answer ...    1\n",
       "other       96     96  Gamingcirclejerk Gaming Circlejerk   Don Chead...    1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower case all entries in category column\n",
    "asd_subs_annotated_df['Category'] = asd_subs_annotated_df['Category'].str.lower()\n",
    "asd_subs_annotated_df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asd</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text                                                               \n",
       "         count unique                                                top freq\n",
       "Category                                                                     \n",
       "asd        113    113  autismmemes autism memes Meme for people with ...    1\n",
       "other       97     97  Gamingcirclejerk Gaming Circlejerk   Don Chead...    1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one entry is miss spelled \n",
    "# replace 'ohter' for 'other' in Category\n",
    "asd_subs_annotated_df['Category'] = asd_subs_annotated_df['Category'].replace('ohter', 'other')\n",
    "asd_subs_annotated_df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is relatively ballanced, with 113 subreddits in the ASD category and 97 in the other (non-ASD) category. \n",
    "\n",
    "In balanced datasets accuracy can be a reasonable measure for assessing the performance of a model. However , other metrics will be used in addition to accuracy, to evaluate the performance of the model: precission, recall and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>asd</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "      <td>asd</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>other</td>\n",
       "      <td>2279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text Category  text_length\n",
       "205  autismmemes autism memes Meme for people with ...      asd           72\n",
       "488  ASDcareers The Careers of People with ASD Livi...      asd         1140\n",
       "231  Gamingcirclejerk Gaming Circlejerk   Don Chead...    other         2279"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the length of text in a new column 'text_tength' \n",
    "asd_subs_annotated_df['text_length'] = asd_subs_annotated_df['text'].apply(lambda x: len(x))\n",
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      210.000000\n",
      "mean      1892.104762\n",
      "std       2271.259118\n",
      "min         22.000000\n",
      "25%        204.500000\n",
      "50%        663.500000\n",
      "75%       3184.000000\n",
      "max      10227.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# text length statisitic for the whole dataset\n",
    "print(asd_subs_annotated_df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram for 'text_length' values\n",
    "plt.hist(asd_subs_annotated_df['text_length'], bins=10, edgecolor='k')\n",
    "\n",
    "# labels and title\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Text Lengths Whole Dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text lenght statistics for Category=other\n",
      "count       97.000000\n",
      "mean      3345.484536\n",
      "std       2478.789818\n",
      "min         22.000000\n",
      "25%       1078.000000\n",
      "50%       3005.000000\n",
      "75%       5186.000000\n",
      "max      10227.000000\n",
      "Name: text_length, dtype: float64\n",
      "\n",
      "text lenght statistics for Category=asd\n",
      "count     113.000000\n",
      "mean      644.513274\n",
      "std       979.758390\n",
      "min        28.000000\n",
      "25%       122.000000\n",
      "50%       324.000000\n",
      "75%       623.000000\n",
      "max      4892.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# show text length for each of the 2 categories\n",
    "# filter rows where 'Category' = 'other'\n",
    "other_df = asd_subs_annotated_df[asd_subs_annotated_df['Category'] == 'other']\n",
    "# filter rows where 'Category' = 'asd'\n",
    "asd_df = asd_subs_annotated_df[asd_subs_annotated_df['Category'] == 'asd']\n",
    "\n",
    "# text lenght statistics for 'Category' = 'other'\n",
    "print('text lenght statistics for Category=other')\n",
    "print(other_df['text_length'].describe())\n",
    "# text lenght statistics for 'Category' = 'asd'\n",
    "print()\n",
    "print('text lenght statistics for Category=asd')\n",
    "print(asd_df['text_length'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram for 'text_length' values of other category\n",
    "plt.hist(other_df['text_length'], bins=10, edgecolor='k')\n",
    "\n",
    "# labels and title\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Text Lengths for Other Category')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram for 'text_length' values of asd category\n",
    "plt.hist(asd_df['text_length'], bins=10, edgecolor='k')\n",
    "\n",
    "# labels and title\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Text Lengths for ASD Category')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average text length for the whole data set is 1892 characters. Text descriptions vary between a minumum of 22 characters to a maximum of 10227 characters. \n",
    "\n",
    "The mean (1892) is almost triple the median value (663). This indicates that the distribution is positively skewed - the tail on the right side (higher values) is longer compared to the left side (lower values), as seen in the histogram above. This indicates that there are some very high values (outliers) pulling the mean upward. \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/07/what-is-skewness-statistics/:\n",
    "Since our data is positively skewed here, it means that it has a higher number of data points having low values (shorter text descriptions). So when we train our model on this data, it will perform better at predicting the category of subreddtis with shorter descriptions as compared to those with longer horsepower. (?)\n",
    "\n",
    "This statistics represent text_lenght in terms of characters (inlcuding white-space). Skewed data is typical in NLP tasks. The text will need to be transformed (tokenisation) and projected into a feature space. \n",
    "All lenght text will be included in the analysis, in order to develop the largest vocabulary possible. \n",
    "As most text descriptions are under 1000 characters, i will expect models to perform best on short text.\n",
    "Also, the 'other' category text data seems to be more balancend, while the 'asd' category seems to containt mostly short text (under 500 chars). Thus i would expect the models to perform better at classifing the other category ( True  negavies). (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "      <th>text_length</th>\n",
       "      <th>asd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "      <td>asd</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "      <td>asd</td>\n",
       "      <td>1140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>other</td>\n",
       "      <td>2279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text Category  text_length  \\\n",
       "205  autismmemes autism memes Meme for people with ...      asd           72   \n",
       "488  ASDcareers The Careers of People with ASD Livi...      asd         1140   \n",
       "231  Gamingcirclejerk Gaming Circlejerk   Don Chead...    other         2279   \n",
       "\n",
       "     asd  \n",
       "205    1  \n",
       "488    1  \n",
       "231    0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category is a categorical variable\n",
    "# needs to be turned into a numerical type for the analysis\n",
    "# create a new column 'Asd' for the numerical values of Category: 0 = Other, 1 = Asd\n",
    "asd_subs_annotated_df['asd']= asd_subs_annotated_df['Category'].apply(lambda x: 1 if x=='asd' else 0)\n",
    "asd_subs_annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210 entries, 205 to 282\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         210 non-null    object\n",
      " 1   Category     210 non-null    object\n",
      " 2   text_length  210 non-null    int64 \n",
      " 3   asd          210 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "asd_subs_annotated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asd</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>autismmemes autism memes Meme for people with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1</td>\n",
       "      <td>ASDcareers The Careers of People with ASD Livi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asd                                               text\n",
       "205    1  autismmemes autism memes Meme for people with ...\n",
       "488    1  ASDcareers The Careers of People with ASD Livi...\n",
       "231    0  Gamingcirclejerk Gaming Circlejerk   Don Chead..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will only use in the following analysis columns text and asd\n",
    "asd_subs_annotated_df_short = asd_subs_annotated_df[['asd', 'text']]\n",
    "asd_subs_annotated_df_short.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train set ( 0.8 of the dataset ) and test set of (0.2 of the dataset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = asd_subs_annotated_df_short[['text']]\n",
    "y = asd_subs_annotated_df_short[['asd']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 168 entries, 116 to 441\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    168 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.6+ KB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 168 entries, 116 to 441\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   asd     168 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.6 KB\n",
      "\n",
      "Asd-Other distribution\n",
      "asd\n",
      "1      90\n",
      "0      78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset')\n",
    "X_train.info()\n",
    "print()\n",
    "y_train.info()\n",
    "print()\n",
    "print('Asd-Other distribution')\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data contains 168 non-null values, and is relatively ballanced (90 subreddits are in the asd category and 78 are in the other category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42 entries, 231 to 426\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    42 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 672.0+ bytes\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42 entries, 231 to 426\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   asd     42 non-null     int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 672.0 bytes\n",
      "\n",
      "Asd-Other distribution\n",
      "asd\n",
      "1      23\n",
      "0      19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Test Dataset')\n",
    "X_test.info()\n",
    "print()\n",
    "y_test.info()\n",
    "print()\n",
    "print('Asd-Other distribution')\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data contains 42 non-null values, and is relatively ballanced (23 subreddits are in the asd category and 19 are in the other category)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both training and testing datasets are cleaned and ready for analysis.\n",
    "Cross validation will be used , instead of a stand alone validation set, due to the small training set size.\n",
    "\n",
    "I will apply different models used for supervised text classification. The best perfomant model will be used further to select the relevant asd(=autism) subreddits from the entire original dataset. \n",
    "\n",
    "List of models used:\n",
    "- text classification with Naive Bayes \n",
    "- text classification with KNeighborsClassifier\n",
    "- text classification with Random Forest\n",
    "- text classification with SVM (lienar = assumes the shape of the decision boundary is linear;  and RBF = for when you don't have prior knowledge about the shape of the decision boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-processing:\n",
    "Text data is unstructured data. Preprocessing this data is a first step to give this data some form of structure. \n",
    "\n",
    "    3.1 split text into tokens/words (=sentence segmentation/ tokanisation NLTK or Spcy or AutoTokenizer if using transformers)\n",
    "\n",
    "    3.3 stemming (=remove prefixes and sufixes) and lemmatization (=get the base word - ext ate becomes (to)eat) - in this project lemmatization will be used as it can more accurately find the base word ( it has more complex rules than stemming -  see https://www.analyticsvidhya.com/blog/2022/06/stemming-vs-lemmatization-in-nlp-must-know-differences/#:~:text=Stemming%20is%20a%20process%20that,form%2C%20which%20is%20called%20Lemma.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>womenonthespectrum womenonthespectrum A commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>The Owl House The Owl House A subreddit for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Autism Speaks Sucks Autism Speaks Sucks A comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "116  womenonthespectrum womenonthespectrum A commun...\n",
       "293  The Owl House The Owl House A subreddit for th...\n",
       "452  Autism Speaks Sucks Autism Speaks Sucks A comm..."
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any stop words ( that were potentially missed by regex above) - > not relevant to the classification task\n",
    "# remove punctuation - not relevant to classification (?maybe)\n",
    "# lemmatize tokens\n",
    "def preprocess(text):\n",
    "    doc= nlp(text)\n",
    "    new_text = []\n",
    "    for t in doc:\n",
    "        if t.is_stop or t.is_punct:\n",
    "            continue\n",
    "        new_text.append(t.lemma_)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>womenonthespectrum womenonthespectrum A commun...</td>\n",
       "      <td>womenonthespectrum womenonthespectrum communit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>The Owl House The Owl House A subreddit for th...</td>\n",
       "      <td>Owl House Owl House subreddit Disney fantasy c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Autism Speaks Sucks Autism Speaks Sucks A comm...</td>\n",
       "      <td>autism speak Sucks autism speak suck community...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "116  womenonthespectrum womenonthespectrum A commun...   \n",
       "293  The Owl House The Owl House A subreddit for th...   \n",
       "452  Autism Speaks Sucks Autism Speaks Sucks A comm...   \n",
       "\n",
       "                                              new_text  \n",
       "116  womenonthespectrum womenonthespectrum communit...  \n",
       "293  Owl House Owl House subreddit Disney fantasy c...  \n",
       "452  autism speak Sucks autism speak suck community...  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process traning set \n",
    "X_train.loc[:, 'new_text'] = X_train['text'].apply(preprocess)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['womenonthespectrum', 'womenonthespectrum', 'A', 'community', 'specifically', 'for', 'women', ' ', 'nonbinary', ' ', 'and', 'afab', 'people', 'on', 'the', 'spectrum', 'to', 'vent', ' ', 'discuss', 'topics', 'related', 'to', 'autism', ' ', 'and', 'support', 'each', 'other', '  ']\n",
      "['womenonthespectrum', 'womenonthespectrum', 'community', 'specifically', 'woman', '  ', 'nonbinary', '  ', 'afab', 'people', 'spectrum', 'vent', '  ', 'discuss', 'topic', 'relate', 'autism', '  ', 'support', '  ']\n"
     ]
    }
   ],
   "source": [
    "# difference in text before and after preprocessing\n",
    "doc_text = nlp(X_train.text[116])\n",
    "doc_new_text = nlp(X_train.new_text[116])\n",
    "print([t.text for t in doc_text])\n",
    "print([t.text for t in doc_new_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk   Don Chead...</td>\n",
       "      <td>Gamingcirclejerk Gaming Circlejerk    Don Chea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ASDpeersupport ASD Peer Support   Peer based s...</td>\n",
       "      <td>ASDpeersupport ASD Peer support    Peer base s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>selfharm A Subreddit for Self Harmers A subred...</td>\n",
       "      <td>selfharm Subreddit Self Harmers subreddit self...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "231  Gamingcirclejerk Gaming Circlejerk   Don Chead...   \n",
       "243  ASDpeersupport ASD Peer Support   Peer based s...   \n",
       "392  selfharm A Subreddit for Self Harmers A subred...   \n",
       "\n",
       "                                              new_text  \n",
       "231  Gamingcirclejerk Gaming Circlejerk    Don Chea...  \n",
       "243  ASDpeersupport ASD Peer support    Peer base s...  \n",
       "392  selfharm Subreddit Self Harmers subreddit self...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process testinf set \n",
    "X_test.loc[:, 'new_text'] = X_test['text'].apply(preprocess)\n",
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 5. 6. Vectorize, Apply Classifier and Evaluate the model - uses sklearn.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. feature engineering (= convert text / document into vector)\n",
    "    count-vector\n",
    "    tf-idf\n",
    "    one-hot encode - not really used due to size and sparcity problems\n",
    "    word/token-emebeding\n",
    "5. apply classifier ( any machine learning model classifier ) - use gridSearchCV to see which is the best performing classifier ?\n",
    "6. evaluate  model: Accuracy, Precision, Recall, F1 score ( if not good , go back to preprocessing step )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def classify(vectorizer, model, x_train, y_train, x_test, y_test, k_folds=5):\n",
    "    # create the pipeline\n",
    "    clf = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # initialize StratifiedKFold for cross-validation\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # perform k-fold (k=5) cross-validation \n",
    "    y_pred_cv = cross_val_predict(clf, x_train, y_train, cv=kf)\n",
    "    \n",
    "    # fit the model on the training data\n",
    "    clf.fit(x_train, y_train)\n",
    "    # make prediction using test data\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # classification report and confusion matrix for cross-validated predictions\n",
    "    print(\"Cross-validated Classification Report:\\n\", classification_report(y_train, y_pred_cv))\n",
    "    print(\"Cross-validated Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred_cv))\n",
    "    \n",
    "    # classification report and confusion matrix for test data \n",
    "    print(\"\\nTest Data Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Test Data Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168,), (168,))"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.asd.shape, X_train.new_text.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n",
      "CountVectorizer() KNeighborsClassifier()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.53      0.68        78\n",
      "           1       0.70      0.98      0.82        90\n",
      "\n",
      "    accuracy                           0.77       168\n",
      "   macro avg       0.83      0.75      0.75       168\n",
      "weighted avg       0.82      0.77      0.75       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[41 37]\n",
      " [ 2 88]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69        19\n",
      "           1       0.72      1.00      0.84        23\n",
      "\n",
      "    accuracy                           0.79        42\n",
      "   macro avg       0.86      0.76      0.76        42\n",
      "weighted avg       0.85      0.79      0.77        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[10  9]\n",
      " [ 0 23]]\n",
      "CountVectorizer() MultinomialNB()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        78\n",
      "           1       0.90      0.96      0.92        90\n",
      "\n",
      "    accuracy                           0.92       168\n",
      "   macro avg       0.92      0.91      0.92       168\n",
      "weighted avg       0.92      0.92      0.92       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[68 10]\n",
      " [ 4 86]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86        19\n",
      "           1       0.85      0.96      0.90        23\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.89      0.87      0.88        42\n",
      "weighted avg       0.89      0.88      0.88        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[15  4]\n",
      " [ 1 22]]\n",
      "CountVectorizer() RandomForestClassifier()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83        78\n",
      "           1       0.82      0.93      0.87        90\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.87      0.85      0.85       168\n",
      "weighted avg       0.86      0.86      0.86       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[60 18]\n",
      " [ 6 84]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76        19\n",
      "           1       0.78      0.91      0.84        23\n",
      "\n",
      "    accuracy                           0.81        42\n",
      "   macro avg       0.82      0.80      0.80        42\n",
      "weighted avg       0.82      0.81      0.81        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[13  6]\n",
      " [ 2 21]]\n",
      "CountVectorizer() SVC(kernel='linear')\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85        78\n",
      "           1       0.84      0.93      0.88        90\n",
      "\n",
      "    accuracy                           0.87       168\n",
      "   macro avg       0.88      0.86      0.87       168\n",
      "weighted avg       0.87      0.87      0.87       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[62 16]\n",
      " [ 6 84]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77        19\n",
      "           1       0.77      1.00      0.87        23\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.88      0.82      0.82        42\n",
      "weighted avg       0.87      0.83      0.83        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[12  7]\n",
      " [ 0 23]]\n",
      "CountVectorizer() SVC()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        78\n",
      "           1       0.77      0.96      0.85        90\n",
      "\n",
      "    accuracy                           0.82       168\n",
      "   macro avg       0.85      0.81      0.81       168\n",
      "weighted avg       0.84      0.82      0.82       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[52 26]\n",
      " [ 4 86]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75        19\n",
      "           1       0.76      0.96      0.85        23\n",
      "\n",
      "    accuracy                           0.81        42\n",
      "   macro avg       0.84      0.79      0.80        42\n",
      "weighted avg       0.83      0.81      0.80        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[12  7]\n",
      " [ 1 22]]\n",
      "\n",
      "TfidfVectorizer()\n",
      "TfidfVectorizer() KNeighborsClassifier()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88        78\n",
      "           1       0.86      0.97      0.91        90\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.91      0.89      0.90       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[64 14]\n",
      " [ 3 87]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86        19\n",
      "           1       0.85      0.96      0.90        23\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.89      0.87      0.88        42\n",
      "weighted avg       0.89      0.88      0.88        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[15  4]\n",
      " [ 1 22]]\n",
      "TfidfVectorizer() MultinomialNB()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        78\n",
      "           1       0.90      0.97      0.93        90\n",
      "\n",
      "    accuracy                           0.92       168\n",
      "   macro avg       0.93      0.92      0.92       168\n",
      "weighted avg       0.93      0.92      0.92       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[68 10]\n",
      " [ 3 87]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86        19\n",
      "           1       0.85      0.96      0.90        23\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.89      0.87      0.88        42\n",
      "weighted avg       0.89      0.88      0.88        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[15  4]\n",
      " [ 1 22]]\n",
      "TfidfVectorizer() RandomForestClassifier()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82        78\n",
      "           1       0.81      0.92      0.86        90\n",
      "\n",
      "    accuracy                           0.85       168\n",
      "   macro avg       0.85      0.84      0.84       168\n",
      "weighted avg       0.85      0.85      0.84       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[59 19]\n",
      " [ 7 83]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        19\n",
      "           1       0.75      0.91      0.82        23\n",
      "\n",
      "    accuracy                           0.79        42\n",
      "   macro avg       0.80      0.77      0.78        42\n",
      "weighted avg       0.80      0.79      0.78        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[12  7]\n",
      " [ 2 21]]\n",
      "TfidfVectorizer() SVC(kernel='linear')\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94        78\n",
      "           1       0.94      0.97      0.95        90\n",
      "\n",
      "    accuracy                           0.95       168\n",
      "   macro avg       0.95      0.94      0.95       168\n",
      "weighted avg       0.95      0.95      0.95       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[72  6]\n",
      " [ 3 87]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91        19\n",
      "           1       0.88      1.00      0.94        23\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.94      0.92      0.93        42\n",
      "weighted avg       0.94      0.93      0.93        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[16  3]\n",
      " [ 0 23]]\n",
      "TfidfVectorizer() SVC()\n",
      "Cross-validated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        78\n",
      "           1       0.90      0.97      0.93        90\n",
      "\n",
      "    accuracy                           0.92       168\n",
      "   macro avg       0.93      0.92      0.92       168\n",
      "weighted avg       0.93      0.92      0.92       168\n",
      "\n",
      "Cross-validated Confusion Matrix:\n",
      " [[68 10]\n",
      " [ 3 87]]\n",
      "\n",
      "Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        19\n",
      "           1       0.85      1.00      0.92        23\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.93      0.89      0.90        42\n",
      "weighted avg       0.92      0.90      0.90        42\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      " [[15  4]\n",
      " [ 0 23]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "vectorizers = [CountVectorizer(), TfidfVectorizer()]\n",
    "models = [KNeighborsClassifier(), MultinomialNB(), RandomForestClassifier(), SVC(kernel='linear'), SVC(kernel='rbf')]\n",
    "\n",
    "for v in vectorizers:\n",
    "    print(v)\n",
    "    for m in models:\n",
    "        print(v, m)\n",
    "        classify(v, m, X_train.new_text, y_train.asd, X_test.new_text, y_test.asd)\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simple frequency word count vectorisation method (CountVectorizer) resulted in an accuracy ranging from 0.79 for the Random Forest and KNN models, to a maximum of 0.88 for the Multinomial Naive Bayse model. The predictions were improved, as expected, when using TF-IDF to vectorize the tokens ( this way frequent words, common to all the documents are given lower importance, and less common words are given more weight): the accuracy of the predictions ranges from 0.79 for the Random Forest model to  0.93 for the SVM with a linear kernel ( the rbf kernel gives a similar accuracy - 0.90 ... ) - how to tell which less likely to ovefit????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to do : use fast text or word2vec + the classification models\n",
    "# to do : text classificatoin with RoBERTa - pytorch and transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
